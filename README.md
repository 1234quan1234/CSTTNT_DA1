# AI Search and Optimization Project

A comprehensive Python framework for comparing **Firefly Algorithm** (FA) with classical optimization methods on continuous and discrete benchmark problems.

## ğŸ¯ Project Overview

This project implements and benchmarks multiple optimization algorithms:

### Swarm Intelligence
- **Firefly Algorithm (FA)** - Continuous optimization
- **Firefly Algorithm (FA)** - Discrete Knapsack variant

### Classical Baselines
- **Hill Climbing** - Greedy local search
- **Simulated Annealing** - Probabilistic local search with temperature scheduling
- **Genetic Algorithm** - Evolutionary optimization
- **Graph Search** - BFS, DFS, A* for graph problems

### Benchmark Problems

#### Continuous Functions
- **Sphere** - Simple convex unimodal function
- **Rosenbrock** - Narrow curved valley (Banana function)
- **Rastrigin** - Highly multimodal with many local minima
- **Ackley** - Multimodal with nearly flat outer region

#### Discrete Problems
- **Traveling Salesman Problem (TSP)** - Find shortest tour
- **0/1 Knapsack** - Maximize value within capacity constraint
- **Graph Coloring** - Minimize color conflicts

## ğŸ“ Project Structure

```
CSTTNT_DA1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                      # Base classes and utilities
â”‚   â”‚   â”œâ”€â”€ base_optimizer.py      # Abstract optimizer interface
â”‚   â”‚   â”œâ”€â”€ problem_base.py        # Abstract problem interface
â”‚   â”‚   â””â”€â”€ utils.py               # Helper functions
â”‚   â”‚
â”‚   â”œâ”€â”€ problems/
â”‚   â”‚   â”œâ”€â”€ continuous/            # Continuous benchmark functions
â”‚   â”‚   â”‚   â”œâ”€â”€ sphere.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rosenbrock.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rastrigin.py
â”‚   â”‚   â”‚   â””â”€â”€ ackley.py
â”‚   â”‚   â””â”€â”€ discrete/              # Discrete optimization problems
â”‚   â”‚       â”œâ”€â”€ tsp.py
â”‚   â”‚       â”œâ”€â”€ knapsack.py
â”‚   â”‚       â””â”€â”€ graph_coloring.py
â”‚   â”‚
â”‚   â”œâ”€â”€ swarm/                     # Swarm intelligence algorithms
â”‚   â”‚   â””â”€â”€ fa.py                  # Firefly Algorithm (continuous & discrete)
â”‚   â”‚
â”‚   â”œâ”€â”€ classical/                 # Classical baseline algorithms
â”‚   â”‚   â”œâ”€â”€ hill_climbing.py
â”‚   â”‚   â”œâ”€â”€ simulated_annealing.py
â”‚   â”‚   â”œâ”€â”€ genetic_algorithm.py
â”‚   â”‚   â””â”€â”€ graph_search.py        # BFS, DFS, A*
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utility modules
â”‚       â””â”€â”€ visualization.py       # Plotting and visualization functions
â”‚
â”œâ”€â”€ test/                          # Unit tests
â”‚   â”œâ”€â”€ test_continuous_problems.py
â”‚   â”œâ”€â”€ test_tsp_problem.py
â”‚   â”œâ”€â”€ test_firefly_algorithm.py
â”‚   â”œâ”€â”€ test_classical_algorithms.py
â”‚   â”œâ”€â”€ run_all_tests.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â””â”€â”€ fa_visualization.ipynb     # Interactive visualization demos
â”‚
â”œâ”€â”€ results/                       # Output directory (auto-created)
â”‚   â”œâ”€â”€ *.png                      # Generated plots
â”‚   â””â”€â”€ *.csv                      # Benchmark results
â”‚
â”œâ”€â”€ demo.py                        # Comprehensive demo script
â”œâ”€â”€ environment.yml                # Conda environment
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ QUICKSTART.md                  # Quick start guide
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10
- NumPy
- SciPy (for optimization baselines)
- Matplotlib (for visualization)
- NetworkX (for graph problems)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/1234quan1234/CSTTNT_DA1.git
cd CSTTNT_DA1
```

2. Install dependencies using conda (recommended):
```bash
conda env create -f environment.yml
conda activate aisearch
```

Or using pip:
```bash
pip install -r requirements.txt
```

### Quick Test

Run the comprehensive demo script:

```bash
python demo.py
```

This will:
- Run FA on Sphere and Rastrigin functions
- Run FA on TSP
- Compare FA with SA, HC, and GA
- Perform parameter sensitivity analysis
- Generate visualization plots in `results/` folder

Or test individual modules:

```bash
# Test Firefly Algorithm
python src/swarm/fa.py

# Test problems
python src/problems/continuous/sphere.py
python src/problems/discrete/tsp.py

# Test visualization utilities
python src/utils/visualization.py

# Run all unit tests
python test/run_all_tests.py
```

## ğŸ’¡ Usage Examples

### Example 1: Continuous Optimization with Firefly Algorithm

```python
import numpy as np
from src.problems.continuous.sphere import SphereProblem
from src.swarm.fa import FireflyContinuousOptimizer

# Create problem
problem = SphereProblem(dim=10)

# Create optimizer
optimizer = FireflyContinuousOptimizer(
    problem=problem,
    n_fireflies=30,
    alpha=0.2,      # Randomization parameter
    beta0=1.0,      # Base attractiveness
    gamma=1.0,      # Light absorption coefficient
    seed=42
)

# Run optimization
best_solution, best_fitness, history, trajectory = optimizer.run(max_iter=100)

print(f"Best fitness: {best_fitness}")
print(f"Best solution: {best_solution}")
```

### Example 2: Knapsack with Discrete Firefly Algorithm

```python
import numpy as np
from src.problems.discrete.knapsack import KnapsackProblem
from src.swarm.fa import FireflyKnapsackOptimizer

# Create Knapsack instance
rng = np.random.RandomState(42)
n_items = 20
values = rng.randint(10, 100, n_items)
weights = rng.randint(1, 50, n_items)
capacity = int(0.5 * np.sum(weights))

problem = KnapsackProblem(values, weights, capacity)

# Create optimizer
optimizer = FireflyKnapsackOptimizer(
    problem=problem,
    n_fireflies=30,
    alpha_flip=0.2,
    max_flips_per_move=3,
    seed=42
)

# Run optimization
best_sol, best_fit, history, trajectory = optimizer.run(max_iter=100)

print(f"Best value: {-best_fit:.2f}")  # Negate because minimization
print(f"Best solution: {best_sol}")
```

### Example 3: Compare Multiple Algorithms

```python
from src.problems.continuous.rastrigin import RastriginProblem
from src.swarm.fa import FireflyContinuousOptimizer
from src.classical.simulated_annealing import SimulatedAnnealingOptimizer
from src.classical.genetic_algorithm import GeneticAlgorithmOptimizer

problem = RastriginProblem(dim=5)

# Firefly Algorithm
fa = FireflyContinuousOptimizer(problem, n_fireflies=20, seed=42)
fa_sol, fa_fit, fa_hist, _ = fa.run(max_iter=100)

# Simulated Annealing
sa = SimulatedAnnealingOptimizer(problem, initial_temp=100, seed=42)
sa_sol, sa_fit, sa_hist, _ = sa.run(max_iter=100)

# Genetic Algorithm
ga = GeneticAlgorithmOptimizer(problem, pop_size=20, seed=42)
ga_sol, ga_fit, ga_hist, _ = ga.run(max_iter=100)

print(f"FA best: {fa_fit:.6f}")
print(f"SA best: {sa_fit:.6f}")
print(f"GA best: {ga_fit:.6f}")
```

## ğŸ“Š Return Format

All optimizers follow the same interface (inherited from `BaseOptimizer`):

```python
best_solution, best_fitness, history_best, trajectory = optimizer.run(max_iter)
```

**Returns:**
- `best_solution` (np.ndarray): Best solution found
  - Continuous: shape (dim,) - real values
  - TSP: shape (n_cities,) - permutation of city indices
  - Knapsack: shape (n_items,) - binary 0/1 array
  - Coloring: shape (n_nodes,) - color assignments
- `best_fitness` (float): Best objective value (minimization)
- `history_best` (List[float]): Best fitness value at each iteration
- `trajectory` (List): Population/solution snapshots at each iteration
  - For population methods: List of population arrays
  - For single-solution methods: List of solution arrays

**Reproducibility:**
All algorithms accept a `seed` parameter (int or None) for reproducible results.
When seed is set, results will be identical across runs **on the same machine**.

```python
# Same seed = same results
optimizer1 = FireflyContinuousOptimizer(problem, seed=42)
optimizer2 = FireflyContinuousOptimizer(problem, seed=42)

sol1, fit1, _, _ = optimizer1.run(max_iter=100)
sol2, fit2, _, _ = optimizer2.run(max_iter=100)

assert fit1 == fit2  # âœ“ Guaranteed
assert np.allclose(sol1, sol2)  # âœ“ Guaranteed
```

**Important:** All optimizers use `np.random.RandomState(seed)` internally
instead of global `np.random` to ensure isolation and reproducibility.
This follows scikit-learn best practices.

## ğŸ”¬ Algorithm Details

### Firefly Algorithm (Continuous)

The continuous FA moves fireflies based on attractiveness and brightness:

```
x_i = x_i + Î²â‚€Â·exp(-Î³Â·rÂ²)Â·(x_j - x_i) + Î±Â·(rand - 0.5)
```

Where:
- `Î²â‚€`: Attractiveness at distance r=0 (default: 1.0)
- `Î³`: Light absorption coefficient (default: 1.0)
- `Î±`: Randomization parameter (default: 0.2)
- `r`: Euclidean distance between fireflies i and j

**Key Properties:**
- Brightness inversely proportional to fitness (minimize problems)
- Less bright fireflies move toward brighter ones
- Movement strength decreases exponentially with distance

**Parameters:**
- `alpha` (0.0-1.0): Controls exploration. Higher = more random movement
- `gamma` (0.0-10.0): Controls attraction decay. Higher = more local search
- `beta0` (0.0-2.0): Base attractiveness at r=0

### Firefly Algorithm (Discrete/Knapsack)

For Knapsack, FA uses bit-flip operators instead of continuous movement:

**Movement Strategy:**
1. Compare current solution with better (brighter) solution
2. Identify bit differences between solutions
3. Apply directed bit flips to align with better solution
4. Add random bit flips (controlled by `alpha_flip`) for exploration
5. Repair infeasible solutions using greedy value/weight ratio

**Parameters:**
- `alpha_flip` (0.0-1.0): Probability of random bit flip after directed movement
- `max_flips_per_move`: Maximum number of directed flips per attraction step
- `repair_method`: "greedy_remove" (recommended) or "random_remove"

### Optimization Problems

| Problem | Type | Dimension | Global Minimum | Domain |
|---------|------|-----------|----------------|--------|
| Sphere | Continuous | Any | f(0,...,0) = 0 | [-5.12, 5.12]^d |
| Rosenbrock | Continuous | â‰¥2 | f(1,...,1) = 0 | [-2.048, 2.048]^d |
| Rastrigin | Continuous | Any | f(0,...,0) = 0 | [-5.12, 5.12]^d |
| Ackley | Continuous | Any | f(0,...,0) = 0 | [-5, 5]^d |
| TSP | Discrete | N cities | Shortest tour | Permutation |
| Knapsack | Discrete | N items | Max value â‰¤ capacity | Binary |
| Graph Coloring | Discrete | N nodes | 0 conflicts | Integer colors |

## ğŸ§ª Testing

Each module includes a `__main__` block with tests. Run tests:

```bash
# Test all continuous problems
python src/problems/continuous/sphere.py
python src/problems/continuous/rosenbrock.py
python src/problems/continuous/rastrigin.py
python src/problems/continuous/ackley.py

# Test all discrete problems
python src/problems/discrete/tsp.py
python src/problems/discrete/knapsack.py
python src/problems/discrete/graph_coloring.py

# Test all optimizers
python src/swarm/fa.py
python src/classical/hill_climbing.py
python src/classical/simulated_annealing.py
python src/classical/genetic_algorithm.py
python src/classical/graph_search.py
```

## ğŸ“– References

1. Yang, X. S. (2008). *Nature-inspired metaheuristic algorithms*. Luniver press.
2. [Firefly Algorithm Overview](https://www.alpsconsult.net/post/firefly-algorithm-fa-overview)
3. [Virtual Library of Simulation Experiments - Test Functions](https://www.sfu.ca/~ssurjano/optimization.html)
4. [Swap-Based Discrete Firefly Algorithm for TSP](https://www.researchgate.net/publication/320480703_Swap-Based_Discrete_Firefly_Algorithm_for_Traveling_Salesman_Problem)

## ğŸ‘¥ Contributors

- BÃ¹i Anh QuÃ¢n (@1234quan1234)

## ğŸ“ License

This project is for educational purposes as part of the CSTTNT course at HCMUS.

---

**Note:** This is a research and educational project implementing classical metaheuristic algorithms.
For production use, consider:
- More optimized implementations (vectorization, JIT compilation)
- Advanced variants (adaptive parameters, hybrid methods)
- Parallel/distributed execution
- Comprehensive benchmarking on standard test suites
